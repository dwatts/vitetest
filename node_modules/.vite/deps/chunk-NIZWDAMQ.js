import {
  t as t3
} from "./chunk-DU3C7D26.js";
import {
  T,
  e2
} from "./chunk-TRGMWULG.js";
import {
  E
} from "./chunk-WTPQKRQM.js";
import {
  e,
  r
} from "./chunk-SMDDCTGQ.js";
import {
  u
} from "./chunk-JP7O2ZWE.js";
import {
  s as s4
} from "./chunk-SGBMUZSF.js";
import {
  D,
  G,
  L,
  f
} from "./chunk-BCDDCNQ2.js";
import {
  n as n2
} from "./chunk-7KH4CLS5.js";
import {
  a
} from "./chunk-WCHO7VLT.js";
import {
  i
} from "./chunk-43LWRDQS.js";
import {
  Z,
  tt
} from "./chunk-ZJEWQGHG.js";
import {
  c,
  s as s3,
  w
} from "./chunk-7I33FAWS.js";
import {
  o,
  t
} from "./chunk-DWOEYHKS.js";
import {
  s2 as s,
  s3 as s2
} from "./chunk-HMVAPW5X.js";
import {
  n2 as n,
  t2
} from "./chunk-JZJWZ6DN.js";

// node_modules/@arcgis/core/libs/basisu/BasisU.js
function t4() {
  if (null == s5) {
    const t5 = (t6) => a(`esri/libs/basisu/${t6}`);
    s5 = import("./basis_transcoder-LFZYQN2W.js").then((e3) => e3.b).then(({ default: e3 }) => e3({ locateFile: t5 }).then((e4) => (e4.initializeBasis(), delete e4.then, e4)));
  }
  return s5;
}
var s5;

// node_modules/@arcgis/core/libs/basisu/TextureFormat.js
var _;
!function(_4) {
  _4[_4.ETC1_RGB = 0] = "ETC1_RGB", _4[_4.ETC2_RGBA = 1] = "ETC2_RGBA", _4[_4.BC1_RGB = 2] = "BC1_RGB", _4[_4.BC3_RGBA = 3] = "BC3_RGBA", _4[_4.BC4_R = 4] = "BC4_R", _4[_4.BC5_RG = 5] = "BC5_RG", _4[_4.BC7_M6_RGB = 6] = "BC7_M6_RGB", _4[_4.BC7_M5_RGBA = 7] = "BC7_M5_RGBA", _4[_4.PVRTC1_4_RGB = 8] = "PVRTC1_4_RGB", _4[_4.PVRTC1_4_RGBA = 9] = "PVRTC1_4_RGBA", _4[_4.ASTC_4x4_RGBA = 10] = "ASTC_4x4_RGBA", _4[_4.ATC_RGB = 11] = "ATC_RGB", _4[_4.ATC_RGBA = 12] = "ATC_RGBA", _4[_4.FXT1_RGB = 17] = "FXT1_RGB", _4[_4.PVRTC2_4_RGB = 18] = "PVRTC2_4_RGB", _4[_4.PVRTC2_4_RGBA = 19] = "PVRTC2_4_RGBA", _4[_4.ETC2_EAC_R11 = 20] = "ETC2_EAC_R11", _4[_4.ETC2_EAC_RG11 = 21] = "ETC2_EAC_RG11", _4[_4.RGBA32 = 13] = "RGBA32", _4[_4.RGB565 = 14] = "RGB565", _4[_4.BGR565 = 15] = "BGR565", _4[_4.RGBA4444 = 16] = "RGBA4444";
}(_ || (_ = {}));

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/BasisUtil.js
var l = null;
var o2 = null;
async function g() {
  return null == o2 && (o2 = t4(), l = await o2), o2;
}
function u2(e3, t5) {
  if (null == l)
    return e3.byteLength;
  const n3 = new l.BasisFile(new Uint8Array(e3)), s7 = E2(n3) ? m(n3.getNumLevels(0), n3.getHasAlpha(), n3.getImageWidth(0, 0), n3.getImageHeight(0, 0), t5) : 0;
  return n3.close(), n3.delete(), s7;
}
function c2(e3, t5) {
  if (null == l)
    return e3.byteLength;
  const n3 = new l.KTX2File(new Uint8Array(e3)), s7 = T2(n3) ? m(n3.getLevels(), n3.getHasAlpha(), n3.getWidth(), n3.getHeight(), t5) : 0;
  return n3.close(), n3.delete(), s7;
}
function m(e3, t5, s7, r2, i3) {
  const l3 = E(t5 ? f.COMPRESSED_RGBA8_ETC2_EAC : f.COMPRESSED_RGB8_ETC2), o4 = i3 && e3 > 1 ? (4 ** e3 - 1) / (3 * 4 ** (e3 - 1)) : 1;
  return Math.ceil(s7 * r2 * l3 * o4);
}
function E2(e3) {
  return e3.getNumImages() >= 1 && !e3.isUASTC();
}
function T2(e3) {
  return e3.getFaces() >= 1 && e3.isETC1S();
}
async function h(e3, t5, n3) {
  null == l && (l = await g());
  const s7 = new l.BasisFile(new Uint8Array(n3));
  if (!E2(s7))
    return null;
  s7.startTranscoding();
  const r2 = p(e3, t5, s7.getNumLevels(0), s7.getHasAlpha(), s7.getImageWidth(0, 0), s7.getImageHeight(0, 0), (e4, t6) => s7.getImageTranscodedSizeInBytes(0, e4, t6), (e4, t6, n4) => s7.transcodeImage(n4, 0, e4, t6, 0, 0));
  return s7.close(), s7.delete(), r2;
}
async function _2(e3, t5, n3) {
  null == l && (l = await g());
  const s7 = new l.KTX2File(new Uint8Array(n3));
  if (!T2(s7))
    return null;
  s7.startTranscoding();
  const r2 = p(e3, t5, s7.getLevels(), s7.getHasAlpha(), s7.getWidth(), s7.getHeight(), (e4, t6) => s7.getImageTranscodedSizeInBytes(e4, 0, 0, t6), (e4, t6, n4) => s7.transcodeImage(n4, e4, 0, 0, t6, 0, -1, -1));
  return s7.close(), s7.delete(), r2;
}
function p(e3, a3, l3, o4, g3, u4, c4, m3) {
  const { compressedTextureETC: E4, compressedTextureS3TC: T4 } = e3.capabilities, [h3, _4] = E4 ? o4 ? [_.ETC2_RGBA, f.COMPRESSED_RGBA8_ETC2_EAC] : [_.ETC1_RGB, f.COMPRESSED_RGB8_ETC2] : T4 ? o4 ? [_.BC3_RGBA, f.COMPRESSED_RGBA_S3TC_DXT5_EXT] : [_.BC1_RGB, f.COMPRESSED_RGB_S3TC_DXT1_EXT] : [_.RGBA32, G.RGBA], p3 = a3.hasMipmap ? l3 : Math.min(1, l3), A = [];
  for (let t5 = 0; t5 < p3; t5++)
    A.push(new Uint8Array(c4(t5, h3))), m3(t5, h3, A[t5]);
  return a3.internalFormat = _4, a3.hasMipmap = A.length > 1, a3.samplingMode = a3.hasMipmap ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, a3.width = g3, a3.height = u4, new T(e3, a3, { type: "compressed", levels: A });
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/DDSUtil.js
var o3 = s.getLogger("esri.views.3d.webgl-engine.lib.DDSUtil");
var a2 = 542327876;
var i2 = 131072;
var l2 = 4;
function s6(e3) {
  return e3.charCodeAt(0) + (e3.charCodeAt(1) << 8) + (e3.charCodeAt(2) << 16) + (e3.charCodeAt(3) << 24);
}
function u3(e3) {
  return String.fromCharCode(255 & e3, e3 >> 8 & 255, e3 >> 16 & 255, e3 >> 24 & 255);
}
var c3 = s6("DXT1");
var h2 = s6("DXT3");
var m2 = s6("DXT5");
var d = 31;
var p2 = 0;
var g2 = 1;
var D2 = 2;
var C = 3;
var f2 = 4;
var w2 = 7;
var T3 = 20;
var _3 = 21;
function E3(e3, r2, o4) {
  const a3 = S(o4, r2.hasMipmap ?? false);
  if (null == a3)
    throw new Error("DDS texture data is null");
  const { textureData: i3, internalFormat: l3, width: s7, height: u4 } = a3;
  return r2.samplingMode = i3.levels.length > 1 ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, r2.hasMipmap = i3.levels.length > 1, r2.internalFormat = l3, r2.width = s7, r2.height = u4, new T(e3, r2, i3);
}
function S(e3, t5) {
  const n3 = new Int32Array(e3, 0, d);
  if (n3[p2] !== a2)
    return o3.error("Invalid magic number in DDS header"), null;
  if (!(n3[T3] & l2))
    return o3.error("Unsupported format, must contain a FourCC code"), null;
  const s7 = n3[_3];
  let E4, S2;
  switch (s7) {
    case c3:
      E4 = 8, S2 = f.COMPRESSED_RGB_S3TC_DXT1_EXT;
      break;
    case h2:
      E4 = 16, S2 = f.COMPRESSED_RGBA_S3TC_DXT3_EXT;
      break;
    case m2:
      E4 = 16, S2 = f.COMPRESSED_RGBA_S3TC_DXT5_EXT;
      break;
    default:
      return o3.error("Unsupported FourCC code:", u3(s7)), null;
  }
  let A = 1, M = n3[f2], x = n3[C];
  0 == (3 & M) && 0 == (3 & x) || (o3.warn("Rounding up compressed texture size to nearest multiple of 4."), M = M + 3 & -4, x = x + 3 & -4);
  const R = M, X = x;
  let b, I;
  n3[D2] & i2 && false !== t5 && (A = Math.max(1, n3[w2]));
  let v = n3[g2] + 4;
  const F = [];
  for (let r2 = 0; r2 < A; ++r2)
    I = (M + 3 >> 2) * (x + 3 >> 2) * E4, b = new Uint8Array(e3, v, I), F.push(b), v += I, M = Math.max(1, M >> 1), x = Math.max(1, x >> 1);
  return { textureData: { type: "compressed", levels: F }, internalFormat: S2, width: R, height: X };
}

// node_modules/@arcgis/core/views/3d/webgl-engine/lib/Texture.js
var w3 = class extends r {
  constructor(t5, r2) {
    super(), this._data = t5, this.type = e.Texture, this._glTexture = null, this._loadingPromise = null, this._loadingController = null, this.events = new n2(), this.parameters = r2 || {}, this.parameters.mipmap = false !== this.parameters.mipmap, this.parameters.noUnpackFlip = this.parameters.noUnpackFlip || false, this.parameters.preMultiplyAlpha = this.parameters.preMultiplyAlpha || false, this.parameters.wrap = this.parameters.wrap || { s: D.REPEAT, t: D.REPEAT }, this._startPreload(t5);
  }
  _startPreload(t5) {
    null != t5 && (t5 instanceof HTMLVideoElement ? this._startPreloadVideoElement(t5) : t5 instanceof HTMLImageElement && this._startPreloadImageElement(t5));
  }
  _startPreloadVideoElement(t5) {
    if (!(Z(t5.src) || "auto" === t5.preload && t5.crossOrigin)) {
      t5.preload = "auto", t5.crossOrigin = "anonymous";
      const e3 = !t5.paused;
      if (t5.src = t5.src, e3 && t5.autoplay) {
        const e4 = () => {
          t5.removeEventListener("canplay", e4), t5.play();
        };
        t5.addEventListener("canplay", e4);
      }
    }
  }
  _startPreloadImageElement(t5) {
    tt(t5.src) || Z(t5.src) || t5.crossOrigin || (t5.crossOrigin = "anonymous", t5.src = t5.src);
  }
  dispose() {
    this._data = void 0;
  }
  _createDescriptor(t5) {
    const e3 = new e2();
    return e3.wrapMode = this.parameters.wrap ?? D.REPEAT, e3.flipped = !this.parameters.noUnpackFlip, e3.samplingMode = this.parameters.mipmap ? L.LINEAR_MIPMAP_LINEAR : L.LINEAR, e3.hasMipmap = !!this.parameters.mipmap, e3.preMultiplyAlpha = !!this.parameters.preMultiplyAlpha, e3.maxAnisotropy = this.parameters.maxAnisotropy ?? (this.parameters.mipmap ? t5.parameters.maxMaxAnisotropy : 1), e3;
  }
  get glTexture() {
    return this._glTexture;
  }
  get memoryEstimate() {
    var _a;
    return ((_a = this._glTexture) == null ? void 0 : _a.gpuMemoryUsage) || H(this._data, this.parameters);
  }
  load(t5) {
    if (null != this._glTexture)
      return this._glTexture;
    if (this._loadingPromise)
      return this._loadingPromise;
    const e3 = this._data;
    return null == e3 ? (this._glTexture = new T(t5, this._createDescriptor(t5), null), this._glTexture) : "string" == typeof e3 ? this._loadFromURL(t5, e3) : e3 instanceof Image ? this._loadFromImageElement(t5, e3) : e3 instanceof HTMLVideoElement ? this._loadFromVideoElement(t5, e3) : e3 instanceof ImageData || e3 instanceof HTMLCanvasElement ? this._loadFromImage(t5, e3) : (n(e3) || t2(e3)) && this.parameters.encoding === u.DDS_ENCODING ? (this._data = void 0, this._loadFromDDSData(t5, e3)) : (n(e3) || t2(e3)) && this.parameters.encoding === u.KTX2_ENCODING ? (this._data = void 0, this._loadFromKTX2(t5, e3)) : (n(e3) || t2(e3)) && this.parameters.encoding === u.BASIS_ENCODING ? (this._data = void 0, this._loadFromBasis(t5, e3)) : t2(e3) ? this._loadFromPixelData(t5, e3) : n(e3) ? this._loadFromPixelData(t5, new Uint8Array(e3)) : null;
  }
  get requiresFrameUpdates() {
    return this._data instanceof HTMLVideoElement;
  }
  frameUpdate(t5) {
    return this._data instanceof HTMLVideoElement && null != this._glTexture ? this._data.readyState < C2.HAVE_CURRENT_DATA || t5 === this._data.currentTime ? t5 : (this._glTexture.setData(this._data), this._glTexture.descriptor.hasMipmap && this._glTexture.generateMipmap(), this.parameters.updateCallback && this.parameters.updateCallback(), this._data.currentTime) : t5;
  }
  _loadFromDDSData(t5, e3) {
    return this._glTexture = E3(t5, this._createDescriptor(t5), e3), this._glTexture;
  }
  _loadFromKTX2(t5, e3) {
    return this._loadAsync(() => _2(t5, this._createDescriptor(t5), e3).then((t6) => (this._glTexture = t6, t6)));
  }
  _loadFromBasis(t5, e3) {
    return this._loadAsync(() => h(t5, this._createDescriptor(t5), e3).then((t6) => (this._glTexture = t6, t6)));
  }
  _loadFromPixelData(t5, e3) {
    s4(this.parameters.width > 0 && this.parameters.height > 0);
    const r2 = this._createDescriptor(t5);
    return r2.pixelFormat = 1 === this.parameters.components ? G.LUMINANCE : 3 === this.parameters.components ? G.RGB : G.RGBA, r2.width = this.parameters.width ?? 0, r2.height = this.parameters.height ?? 0, this._glTexture = new T(t5, r2, e3), this._glTexture;
  }
  _loadFromURL(t5, e3) {
    return this._loadAsync(async (r2) => {
      const a3 = await t3(e3, { signal: r2 });
      return s3(r2), this._loadFromImage(t5, a3);
    });
  }
  _loadFromImageElement(t5, e3) {
    return e3.complete ? this._loadFromImage(t5, e3) : this._loadAsync(async (r2) => {
      const a3 = await i(e3, e3.src, false, r2);
      return s3(r2), this._loadFromImage(t5, a3);
    });
  }
  _loadFromVideoElement(t5, e3) {
    return e3.readyState >= C2.HAVE_CURRENT_DATA ? this._loadFromImage(t5, e3) : this._loadFromVideoElementAsync(t5, e3);
  }
  _loadFromVideoElementAsync(e3, r2) {
    return this._loadAsync((s7) => new Promise((n3, l3) => {
      const m3 = () => {
        r2.removeEventListener("loadeddata", h3), r2.removeEventListener("error", p3), o(d2);
      }, h3 = () => {
        r2.readyState >= C2.HAVE_CURRENT_DATA && (m3(), n3(this._loadFromImage(e3, r2)));
      }, p3 = (e4) => {
        m3(), l3(e4 || new s2("Failed to load video"));
      };
      r2.addEventListener("loadeddata", h3), r2.addEventListener("error", p3);
      const d2 = w(s7, () => p3(c()));
    }));
  }
  _loadFromImage(t5, e3) {
    const r2 = N(e3);
    this.parameters.width = r2.width, this.parameters.height = r2.height;
    const a3 = this._createDescriptor(t5);
    return a3.pixelFormat = 3 === this.parameters.components ? G.RGB : G.RGBA, a3.width = r2.width, a3.height = r2.height, this._glTexture = new T(t5, a3, e3), this._glTexture;
  }
  _loadAsync(t5) {
    const e3 = new AbortController();
    this._loadingController = e3;
    const r2 = t5(e3.signal);
    this._loadingPromise = r2;
    const a3 = () => {
      this._loadingController === e3 && (this._loadingController = null), this._loadingPromise === r2 && (this._loadingPromise = null);
    };
    return r2.then(a3, a3), r2;
  }
  unload() {
    if (this._glTexture = t(this._glTexture), null != this._loadingController) {
      const t5 = this._loadingController;
      this._loadingController = null, this._loadingPromise = null, t5.abort();
    }
    this.events.emit("unloaded");
  }
};
function H(t5, e3) {
  if (null == t5)
    return 0;
  if (n(t5) || t2(t5))
    return e3.encoding === u.KTX2_ENCODING ? c2(t5, !!e3.mipmap) : e3.encoding === u.BASIS_ENCODING ? u2(t5, !!e3.mipmap) : t5.byteLength;
  const { width: r2, height: a3 } = t5 instanceof Image || t5 instanceof ImageData || t5 instanceof HTMLCanvasElement || t5 instanceof HTMLVideoElement ? N(t5) : e3;
  return (e3.mipmap ? 4 / 3 : 1) * r2 * a3 * (e3.components || 4) || 0;
}
function N(t5) {
  return t5 instanceof HTMLVideoElement ? { width: t5.videoWidth, height: t5.videoHeight } : t5;
}
var C2;
!function(t5) {
  t5[t5.HAVE_NOTHING = 0] = "HAVE_NOTHING", t5[t5.HAVE_METADATA = 1] = "HAVE_METADATA", t5[t5.HAVE_CURRENT_DATA = 2] = "HAVE_CURRENT_DATA", t5[t5.HAVE_FUTURE_DATA = 3] = "HAVE_FUTURE_DATA", t5[t5.HAVE_ENOUGH_DATA = 4] = "HAVE_ENOUGH_DATA";
}(C2 || (C2 = {}));

export {
  g,
  w3 as w
};
//# sourceMappingURL=chunk-NIZWDAMQ.js.map
